{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import doc2vec\n",
    "from scipy.spatial import distance\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/hugoperrin/Bureau/Datasets/ToxicComment/'\n",
    "\n",
    "train=pd.read_csv(path + 'train.csv')\n",
    "test=pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 8), (153164, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de commentaires: 159571\n",
      "Nombre de toxic: 15294\n",
      "Nombre de severe_toxic: 1595\n",
      "Nombre de obscene: 8449\n",
      "Nombre de threat: 478\n",
      "Nombre de identity hate: 1405\n",
      "Nombre de insult: 7877\n"
     ]
    }
   ],
   "source": [
    "print('Nombre de commentaires:', train.shape[0])\n",
    "print('Nombre de toxic:', train[train['toxic']==1].shape[0])\n",
    "print('Nombre de severe_toxic:', train[train['severe_toxic']==1].shape[0])\n",
    "print('Nombre de obscene:', train[train['obscene']==1].shape[0])\n",
    "print('Nombre de threat:', train[train['threat']==1].shape[0])\n",
    "print('Nombre de identity hate:', train[train['identity_hate']==1].shape[0])\n",
    "print('Nombre de insult:', train[train['insult']==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0020e7119b96eeeb</td>\n",
       "      <td>Stupid peace of shit stop deleting my stuff as...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0020fd96ed3b8c8b</td>\n",
       "      <td>=Tony Sidaway is obviously a fistfuckee. He lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "55  0020e7119b96eeeb  Stupid peace of shit stop deleting my stuff as...   \n",
       "56  0020fd96ed3b8c8b  =Tony Sidaway is obviously a fistfuckee. He lo...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6       1             1        1       0       1              0  \n",
       "42      1             0        1       0       1              1  \n",
       "43      1             0        1       0       1              0  \n",
       "55      1             1        1       0       1              0  \n",
       "56      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['insult']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de commentaires considéré comme insulte non toxiques: 533\n",
      "On en déduit que tous les commentaires classé dans une catégories ne sont pas nécessairement toxiques \n"
     ]
    }
   ],
   "source": [
    "print('Nombre de commentaires considéré comme insulte non toxiques:',train[(train['toxic']==0)&(train['insult']==1)].shape[0])\n",
    "print('On en déduit que tous les commentaires classé dans une catégories ne sont pas nécessairement toxiques ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_words(raw_text, remove_stopwords):\n",
    "    \n",
    "    # 1. Remove non-letters, but including numbers\n",
    "    letters_only = re.sub(\"[^0-9a-zA-Z]\", \" \", raw_text)\n",
    "    \n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\")) # In Python, searching a set is much faster\n",
    "        meaningful_words = [w for w in words if not w in stops] # Remove stop words\n",
    "        words = meaningful_words\n",
    "    return words \n",
    "\n",
    "# With stop words\n",
    "sentences_train = train['comment_text'].apply(text_to_words, remove_stopwords=False)\n",
    "sentences_test = test['comment_text'].apply(text_to_words, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots moyen: 69, nombre de mots médian: 37\n"
     ]
    }
   ],
   "source": [
    "p = Pool()\n",
    "length = np.array(p.map(len, sentences_train))\n",
    "p.close()\n",
    "print('Nombre de mots moyen: %d, nombre de mots médian: %d' %(np.mean(length),np.median(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de commentaires: 312735\n"
     ]
    }
   ],
   "source": [
    "print('Nombre total de commentaires: %d' %len(sentences_train.tolist()+sentences_test.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 49s, sys: 1.31 s, total: 3min 50s\n",
      "Wall time: 57.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Word2Vec on train & test comments\n",
    "model = Word2Vec(sentences_train.tolist()+sentences_test.tolist(), min_count=1, size=100, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 309869\n"
     ]
    }
   ],
   "source": [
    "print('Vocab size: %d' %len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fucking', 0.6382911801338196),\n",
       " ('cunt', 0.6099342107772827),\n",
       " ('hell', 0.6068971157073975),\n",
       " ('bitch', 0.585590124130249),\n",
       " ('piss', 0.5641528964042664),\n",
       " ('damn', 0.5607340335845947),\n",
       " ('shit', 0.5599602460861206),\n",
       " ('motherfucker', 0.542536199092865),\n",
       " ('dumbass', 0.5193943977355957),\n",
       " ('asshole', 0.5075051784515381)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('fuck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final matrix embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_matrix(comment):\n",
    "    try:\n",
    "        max_word = 30\n",
    "\n",
    "        if len(comment) >= max_word:\n",
    "            mat = model.wv[comment[:max_word]]\n",
    "        else:\n",
    "            mat = model.wv[comment[:max_word]]\n",
    "            mat = np.concatenate((mat, np.zeros((max_word-len(comment),100),dtype=\"float32\")), axis = 0)\n",
    "\n",
    "        mat[max_word-1,]=model.wv[comment].sum(0)/len(comment)\n",
    "    except:\n",
    "        mat = np.zeros((max_word,100),dtype=\"float32\")\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "train = pool.map(get_matrix, sentences_train)\n",
    "pool.close()\n",
    "np.save('/home/hugoperrin/Bureau/Datasets/ToxicComment/Comment2Vec_train_vM.npy', np.array(train))\n",
    "del train, sentences_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train done\n"
     ]
    }
   ],
   "source": [
    "print('Train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "test = pool.map(get_matrix, sentences_test)\n",
    "pool.close()\n",
    "np.save('/home/hugoperrin/Bureau/Datasets/ToxicComment/Comment2Vec_test_vM.npy', np.array(test))\n",
    "del test, sentences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test done\n"
     ]
    }
   ],
   "source": [
    "print('Test done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stop here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
