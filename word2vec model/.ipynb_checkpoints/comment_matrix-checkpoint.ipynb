{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import doc2vec\n",
    "from scipy.spatial import distance\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/hugoperrin/Bureau/Datasets/ToxicComment/'\n",
    "\n",
    "train=pd.read_csv(path + 'train.csv')\n",
    "test=pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 8), (153164, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comment_list=train['comment_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de commentaires: 159571\n",
      "Nombre de toxic: 15294\n",
      "Nombre de severe_toxic: 1595\n",
      "Nombre de obscene: 8449\n",
      "Nombre de threat: 478\n",
      "Nombre de identity hate: 1405\n",
      "Nombre de insult: 7877\n"
     ]
    }
   ],
   "source": [
    "print('Nombre de commentaires:', train.shape[0])\n",
    "print('Nombre de toxic:', train[train['toxic']==1].shape[0])\n",
    "print('Nombre de severe_toxic:', train[train['severe_toxic']==1].shape[0])\n",
    "print('Nombre de obscene:', train[train['obscene']==1].shape[0])\n",
    "print('Nombre de threat:', train[train['threat']==1].shape[0])\n",
    "print('Nombre de identity hate:', train[train['identity_hate']==1].shape[0])\n",
    "print('Nombre de insult:', train[train['insult']==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0020e7119b96eeeb</td>\n",
       "      <td>Stupid peace of shit stop deleting my stuff as...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0020fd96ed3b8c8b</td>\n",
       "      <td>=Tony Sidaway is obviously a fistfuckee. He lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "55  0020e7119b96eeeb  Stupid peace of shit stop deleting my stuff as...   \n",
       "56  0020fd96ed3b8c8b  =Tony Sidaway is obviously a fistfuckee. He lo...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6       1             1        1       0       1              0  \n",
       "42      1             0        1       0       1              1  \n",
       "43      1             0        1       0       1              0  \n",
       "55      1             1        1       0       1              0  \n",
       "56      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['insult']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de commentaires considéré comme insulte non toxiques: 533\n",
      "On en déduit que tous les commentaires classé dans une catégories ne sont pas nécessairement toxiques \n"
     ]
    }
   ],
   "source": [
    "print('Nombre de commentaires considéré comme insulte non toxiques:',train[(train['toxic']==0)&(train['insult']==1)].shape[0])\n",
    "print('On en déduit que tous les commentaires classé dans une catégories ne sont pas nécessairement toxiques ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec les stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_words(raw_text, remove_stopwords):\n",
    "    # 1. Remove non-letters, but including numbers\n",
    "    letters_only = re.sub(\"[^0-9a-zA-Z]\", \" \", raw_text)\n",
    "    #letters_only = re.sub(\"[^0-9a-zA-Z]\", \" \", raw_text)\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\")) # In Python, searching a set is much faster than searching\n",
    "        meaningful_words = [w for w in words if not w in stops] # Remove stop words\n",
    "        words = meaningful_words\n",
    "    return words \n",
    "\n",
    "sentences_train = train['comment_text'].apply(text_to_words, remove_stopwords=False)\n",
    "sentences_test = test['comment_text'].apply(text_to_words, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments=sentences_train.tolist()+sentences_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = np.array(Pool().map(len, sentences_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312735"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation des word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 59s, sys: 1.18 s, total: 4min 1s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%time model = Word2Vec(comments, min_count=1, size=100, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309869"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paper', 0.7970813512802124),\n",
       " ('books', 0.7366164922714233),\n",
       " ('novel', 0.6929596066474915),\n",
       " ('poem', 0.6892553567886353),\n",
       " ('story', 0.6795624494552612),\n",
       " ('poetry', 0.6292711496353149),\n",
       " ('webpage', 0.625411868095398),\n",
       " ('document', 0.6240420341491699),\n",
       " ('writings', 0.6213411092758179),\n",
       " ('publication', 0.6170291900634766)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(comment):\n",
    "    \n",
    "    try:\n",
    "        max_word = 50\n",
    "\n",
    "        if len(comment) >= max_word:\n",
    "            mat = model.wv[comment[:max_word]]\n",
    "        else:\n",
    "            mat = model.wv[comment[:max_word]]\n",
    "            mat = np.concatenate((mat, np.zeros((max_word-len(comment),100),dtype=\"float32\")), axis = 0)\n",
    "\n",
    "        mat[max_word-1,]=model.wv[comment].sum(0)/len(comment)\n",
    "    except:\n",
    "        mat = np.zeros((max_word,100),dtype=\"float32\")\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "train = pool.map(get_matrix, sentences_train)\n",
    "pool.close()\n",
    "np.save('/home/hugoperrin/Bureau/Datasets/ToxicComment/Comment2Vec_train_vM.npy', np.array(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "test = pool.map(get_matrix, sentences_test)\n",
    "pool.close()\n",
    "np.save('/home/hugoperrin/Bureau/Datasets/ToxicComment/Comment2Vec_train_vM.npy', np.array(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stop here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
